{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3wH4af9ZLRd",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*   Link to challange associated with dataset: https://kits21.kits-challenge.org/org/home/\n",
    "*   Link to dataset github info: https://github.com/neheller/kits21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-TMD6x3hpo1j",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "KiTS21 dataset: A collection of multi-phase CT imaging, segmentation masks, and comprehensive clinical outcomes for 300 patients who underwent nephrectomy for kidney tumors between 2010 and 2018. 210 (70%) of these patients were selected at random as the training set for the 2019 MICCAI KiTS Kidney Tumor Segmentation Challenge and have been released publicly. \n",
    "\n",
    "With the presence of clinical context and surgical outcomes, this data can serve not only for benchmarking semantic segmentation models, but also for developing and studying biomarkers which make use of the imaging and semantic segmentation masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "798qW55hNa2N",
    "outputId": "1670f63d-6e9e-43d2-828d-94a7cfe5f78c",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Setting up the env by downloading all the packages needed\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "import cv2\n",
    "import nibabel as nib \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.layers.experimental import preprocessing \n",
    "from tensorflow.keras.optimizers import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gY5AJpsG3cop",
    "outputId": "23f5bff7-a38d-4d8f-bb89-0d0bda2e1365",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Downloads a software package from GitHub called \"kits19\" and saves it to the root directory of the current working environment\n",
    "#%cd /Users/syn/Documents/GitHub/KidneySegmentation/kits211\n",
    "#!git clone https://github.com/neheller/kits21.git\n",
    "#%cd /Users/syn/Documents/GitHub/KidneySegmentation/kits211kits21/ #changes the current directory to \"/Users/syn/Documents/GitHub/KidneySegmentation/kits211kits19/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hTJ06ihg00iI",
    "outputId": "a5c87919-f34c-4929-9455-6cb8f43e04e4",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#search_dir = '/'\n",
    "#for root, dirs, files in os.walk(search_dir):\n",
    "#    if 'kits21' in dirs:\n",
    "#        kits21_dir = os.path.join(root, 'kits21')\n",
    "#        print(f\"The 'kits21' directory is located at {kits21_dir}\")\n",
    "#        break\n",
    "#else:\n",
    "#    print(\"The 'kits21' directory was not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#import subprocess\n",
    "\n",
    "# Set the path to the directory containing the setup.py file\n",
    "#path_to_setup = '/Users/syn/Documents/GitHub/KidneySegmentation/kits211kits21/'\n",
    "\n",
    "# Run the command to install the repository\n",
    "#subprocess.call(['pip', 'install', '-e', path_to_setup])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r3gdJds56LC4",
    "outputId": "648bfe81-0081-4459-eff3-84ac54895f95",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#imaging is not stored in the repository, it must be downloaded using one of the get_imaging scripts in the starter_code directory. \n",
    "#!ls /Users/syn/Documents/GitHub/KidneySegmentation/kits211kits21/kits21/starter_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OkeTP0juVDFM",
    "outputId": "672e0539-b13d-4a66-a923-2b00563eda59",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#%cd /Users/syn/Documents/GitHub/KidneySegmentation/kits211kits21/kits21/starter_code\n",
    "#!python /Users/syn/Documents/GitHub/KidneySegmentation/kits211kits21/kits21/starter_code/get_imaging.py #running a Python script named \"get_imaging.py\" located in the directory \"/Users/syn/Documents/GitHub/KidneySegmentation/kits211kits21/starter_code/\" to get the dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ZhHfyb37Ueq",
    "outputId": "66846e20-b9ef-4a59-bf0f-498621d9a231",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#!ls /Users/syn/Documents/GitHub/KidneySegmentation/kits211kits21/kits21/data/case_00000/segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "id": "eJ6Ffd9oEdqQ",
    "outputId": "2f32e64a-ca2c-4fdc-913a-1bfb3acd19ae",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Defines the file paths for the CT image and segmentation mask\n",
    "ct_path = \"/Users/syn/Documents/GitHub/KidneySegmentation/kits21/kits21/data/case_00026/imaging.nii.gz\"\n",
    "segmentation_path1 = \"/Users/syn/Documents/GitHub/KidneySegmentation/kits21/kits21/data/case_00026/segmentations/kidney_instance-1_annotation-1.nii.gz\"\n",
    "segmentation_path2 = \"/Users/syn/Documents/GitHub/KidneySegmentation/kits21/kits21/data/case_00026/segmentations/tumor_instance-1_annotation-1.nii.gz\"\n",
    "\n",
    "#Loads the CT image and segmentation mask using nibabel\n",
    "ct = nib.load(ct_path).get_fdata()\n",
    "segmentation1 = nib.load(segmentation_path1).get_fdata()\n",
    "segmentation2 = nib.load(segmentation_path2).get_fdata()\n",
    "\n",
    "#Sets the color map range to adjust the contrast\n",
    "vmin_ct = np.min(ct)\n",
    "vmax_ct = np.max(ct)\n",
    "vmin_seg = 0\n",
    "vmax_seg = 1\n",
    "\n",
    "#Displays multiple slices of the CT image and segmentation mask\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "axs[0, 0].imshow(np.rot90(ct[:, :, 50]), cmap='gray', vmin=vmin_ct, vmax=vmax_ct)\n",
    "axs[0, 0].set_title('CT Slice 50')\n",
    "axs[0, 1].imshow(np.rot90(ct[:, :, 100]), cmap='gray', vmin=vmin_ct, vmax=vmax_ct)\n",
    "axs[0, 1].set_title('CT Slice 100')\n",
    "axs[0, 2].imshow(np.rot90(ct[:, :, 150]), cmap='gray', vmin=vmin_ct, vmax=vmax_ct)\n",
    "axs[0, 2].set_title('CT Slice 150')\n",
    "\n",
    "axs[1, 0].imshow(np.rot90(np.max(segmentation1, axis=-1)), cmap='gray', vmin=vmin_seg, vmax=vmax_seg)\n",
    "axs[1, 0].set_title('Segmentation Mask 1 Kidney')\n",
    "axs[1, 1].axis('off') # remove empty subplot\n",
    "axs[1, 2].imshow(np.rot90(np.max(segmentation2, axis=-1)), cmap='gray', vmin=vmin_seg, vmax=vmax_seg)\n",
    "axs[1, 2].set_title('Segmentation Mask 2 Tumor')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 838
    },
    "id": "T_51g57QHF9E",
    "outputId": "9c46ba0b-0d77-4b51-b9e0-fa892cb654fa",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Defines the file paths for the CT image and segmentation mask\n",
    "ct_path = \"/Users/syn/Documents/GitHub/KidneySegmentation/kits21/kits21/data/case_00095/imaging.nii.gz\"\n",
    "segmentation_path1 = \"/Users/syn/Documents/GitHub/KidneySegmentation/kits21/kits21/data/case_00095/segmentations/kidney_instance-1_annotation-1.nii.gz\"\n",
    "segmentation_path2 = \"/Users/syn/Documents/GitHub/KidneySegmentation/kits21/kits21/data/case_00095/segmentations/tumor_instance-1_annotation-1.nii.gz\"\n",
    "\n",
    "#Loads the CT image and segmentation mask using nibabel\n",
    "ct = nib.load(ct_path).get_fdata()\n",
    "segmentation1 = nib.load(segmentation_path1).get_fdata()\n",
    "segmentation2 = nib.load(segmentation_path2).get_fdata()\n",
    "\n",
    "#Sets the color map range to adjust the contrast\n",
    "#vmin_ct = np.min(ct) #too dark\n",
    "#vmax_ct = np.max(ct) #too dark\n",
    "vmin_ct = np.percentile(ct, 1) # set vmin_ct to the 1st percentile of pixel values\n",
    "vmax_ct = np.percentile(ct, 99) # set vmax_ct to the 99th percentile of pixel values\n",
    "vmin_seg = 0\n",
    "vmax_seg = 1\n",
    "\n",
    "#Noticing that for some cases, the graph is coming out squished so we want to fix that\n",
    "# Calculate the aspect ratio of the image\n",
    "height, width, _ = ct.shape\n",
    "aspect = height / width\n",
    "\n",
    "#Displays the CT image and segmentation masks overlaid on slice 150\n",
    "#fig, ax = plt.subplots(figsize=(8, 8)) #old code that outputs squished graph for some cases\n",
    "fig, ax = plt.subplots(figsize=(16, 16*aspect))\n",
    "\n",
    "ax.imshow(np.rot90(ct[:, :, 150]), cmap='gray', vmin=vmin_ct, vmax=vmax_ct, aspect=aspect)\n",
    "ax.imshow(np.rot90(np.max(segmentation1, axis=-1)), cmap='gray', alpha=0.5, vmin=vmin_seg, vmax=vmax_seg, aspect=aspect)\n",
    "ax.imshow(np.rot90(np.max(segmentation2, axis=-1)), cmap='gray', alpha=0.5, vmin=vmin_seg, vmax=vmax_seg, aspect=aspect)\n",
    "\n",
    "ax.set_title('CT Slice 150 with Overlaid Segmentation Masks')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyzw5UAoSLT6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We want to start creating the training data from the available data that we have. We noticed that there is a lot of information we dont want to use so we established a workflow to extract the information that we wanted:\n",
    "\n",
    "1. Define the paths to the data and output directories\n",
    "2. Define the filenames of the segmentation files we want to extract\n",
    "3. Loop over all cases in the data directory\n",
    "4. For each case, load slice 150 of the CT scan as a numpy array\n",
    "5. Create a subdirectory for each case in the output directory\n",
    "6. Save the corresponding CT slice image in the output directory\n",
    "7. For each segmentation file, load the segmentation as a numpy array\n",
    "8. Create a binary mask for the corresponding kidney instance\n",
    "9. Save each mask image in the output directory, with a filename indicating the kidney instance number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kmllyj8rIvAd",
    "outputId": "8fb6b99b-af9e-494f-ff9f-c9ff0b530aac",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import nibabel as nib\n",
    "# import matplotlib.pyplot as plt\n",
    "#\n",
    "# # Here we define the paths to the data and output directories\n",
    "# data_dir = \"/Users/syn/Documents/GitHub/KidneySegmentation/kits21/kits21/data\"\n",
    "# output_dir = \"/Users/syn/Documents/GitHub/KidneySegmentation/kits21/kidney_detection_training_data_preprocessed/\"\n",
    "#\n",
    "# # Here we define the filenames of the segmentation files we want to extract\n",
    "# segmentation_filenames = [\"kidney_instance-1_annotation-1.nii.gz\",\n",
    "#                           \"kidney_instance-1_annotation-2.nii.gz\",\n",
    "#                           \"kidney_instance-1_annotation-3.nii.gz\",\n",
    "#                           \"kidney_instance-2_annotation-1.nii.gz\",\n",
    "#                           \"kidney_instance-2_annotation-2.nii.gz\",\n",
    "#                           \"kidney_instance-2_annotation-3.nii.gz\"]\n",
    "#\n",
    "# # For each case in the data, we want to create a loop to look through them\n",
    "# for case_dir in os.listdir(data_dir):\n",
    "#     # Lets make sure we're only looking at directories and not files\n",
    "#     if os.path.isdir(os.path.join(data_dir, case_dir)):\n",
    "#         # Here we define the paths to the CT and segmentation files for each case\n",
    "#         ct_path = os.path.join(data_dir, case_dir, \"imaging.nii.gz\")\n",
    "#         segmentation_paths = [os.path.join(data_dir, case_dir, \"segmentations\", filename) for filename in segmentation_filenames]\n",
    "#\n",
    "#         # We want to check if slice 150 of the CT scan and all the annotations exist\n",
    "#         if not os.path.isfile(ct_path):\n",
    "#             print(f\"Skipping case {case_dir} because CT scan file not found\")\n",
    "#             continue\n",
    "#\n",
    "#         for segmentation_path in segmentation_paths:\n",
    "#             if not os.path.isfile(segmentation_path):\n",
    "#                 print(f\"Skipping case {case_dir} because segmentation file not found: {segmentation_path}\")\n",
    "#                 break\n",
    "#         else:\n",
    "#             # Lets load slice 150 of the CT scan as a numpy array\n",
    "#             ct_slice = nib.load(ct_path).get_fdata()[:, :, 150]\n",
    "#\n",
    "#             # Here we define the output directory for each case\n",
    "#             output_case_dir = os.path.join(output_dir, case_dir)\n",
    "#             os.makedirs(output_case_dir, exist_ok=True)\n",
    "#\n",
    "#             # We want to preprocess the CT slice before saving it into the output directory\n",
    "#             ct_slice = ct_slice.astype(np.float32)\n",
    "#             ct_slice -= np.mean(ct_slice)\n",
    "#             ct_slice /= np.std(ct_slice)\n",
    "#             ct_slice = np.clip(ct_slice, -3.0, 3.0)\n",
    "#             ct_slice = (ct_slice + 3.0) / 6.0\n",
    "#             ct_slice_ext = os.path.splitext(os.path.basename(ct_path))[1].split(\".\")[1] # extract the file extension from the original file\n",
    "#             ct_slice_path = os.path.join(output_case_dir, f\"ct{ct_slice_ext}\")\n",
    "#             nib.save(nib.Nifti1Image(ct_slice, np.eye(4)), ct_slice_path)\n",
    "#\n",
    "#             # We want to loop over each segmentation file and save the corresponding mask\n",
    "#             for i, segmentation_path in enumerate(segmentation_paths):\n",
    "#                 segmentation = nib.load(segmentation_path).get_fdata()\n",
    "#                 mask = (segmentation[:, :, 150] == i+1).astype(np.uint8)\n",
    "#                 mask_ext = os.path.splitext(os.path.basename(segmentation_path))[1] # extract the file extension from the original file\n",
    "#                 mask_name = os.path.splitext(os.path.basename(segmentation_path))[0] # extract the segmentation filename without extension\n",
    "#                 mask_path = os.path.join(output_case_dir, f\"{mask_name}{mask_ext}\")\n",
    "#                 nib.save(nib.Nifti1Image(mask, np.eye(4)), mask_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IF8ROb7Olvvt",
    "outputId": "54bdb9f1-2b5c-4831-8c75-c882dfe4f2ec",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!ls /Users/syn/Documents/GitHub/KidneySegmentation/kits21/kidney_detection_training_data_preprocessed/case_00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXbEFdq8gyA3",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# DATA_PATH = \"/Users/syn/Documents/GitHub/KidneySegmentation/kits21/kidney_detection_training_data_preprocessed\"\n",
    "#\n",
    "# # Loop through all subdirectories in DATA_PATH\n",
    "# for subdir in os.listdir(DATA_PATH):\n",
    "#     subdir_path = os.path.join(DATA_PATH, subdir)\n",
    "#\n",
    "#     # Loop through all files in the subdirectory\n",
    "#     for file in os.listdir(subdir_path):\n",
    "#         if file.endswith(\".png\"):\n",
    "#             # If the file ends with .png, delete it\n",
    "#             os.remove(os.path.join(subdir_path, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ynoGo-DgzZI",
    "outputId": "a6233b36-2e35-4d53-965e-804966d44c2e",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#!ls /Users/syn/Documents/GitHub/KidneySegmentation/kits21/kidney_detection_training_data_preprocessed/case_00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "id": "oN_CR07uleO6",
    "outputId": "2ad84aa9-6e9a-48f2-f11a-141fddfcd190",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the file paths\n",
    "ct_file = '/Users/syn/Documents/GitHub/KidneySegmentation/kits21/kidney_detection_training_data_preprocessed/case_00081/ctgz.nii'\n",
    "mask_file = '/Users/syn/Documents/GitHub/KidneySegmentation/kits21/kidney_detection_training_data_preprocessed/case_00081/kidney_instance-1_annotation-1.nii.gz'\n",
    "\n",
    "# Load the CT slice and segmentation mask\n",
    "ct_nii = nib.load(ct_file)\n",
    "ct_slice = ct_nii.get_fdata()\n",
    "\n",
    "mask_nii = nib.load(mask_file)\n",
    "segmentation_mask = mask_nii.get_fdata()\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot the CT slice on the first subplot\n",
    "axs[0].imshow(ct_slice, cmap='gray')\n",
    "axs[0].set_title('CT Slice')\n",
    "\n",
    "# Plot the segmentation mask on the second subplot\n",
    "axs[1].imshow(segmentation_mask, cmap='gray')\n",
    "axs[1].set_title('Segmentation Mask')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0TrmF0uhuTKT",
    "outputId": "3ad7fbfa-88e9-4d3c-9bf5-1cf133626fbf",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set the directory path\n",
    "TRAIN_DATA_PATH = \"/Users/syn/Documents/GitHub/KidneySegmentation/kits21/kidney_detection_training_data_preprocessed/\"\n",
    "\n",
    "# Let's create the training, validation and test ids.\n",
    "\n",
    "train_dir = [f.path for f in os.scandir(TRAIN_DATA_PATH) if f.is_dir()]\n",
    "\n",
    "# We will create train, validation and test ids from the train_dir dataset\n",
    "\n",
    "\n",
    "def list_to_ids(dir:str):\n",
    "    \"\"\"\n",
    "    Will convert the dir paths to ids by parsing the paths.\n",
    "    dir: string, image dir paths in BRATS\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    for i in range(0,len(dir)):\n",
    "        x.append(dir[i].split('/')[-1])\n",
    "    return x\n",
    "\n",
    "# Now let's use the defined function\n",
    "\n",
    "ids = list_to_ids(train_dir) \n",
    "\n",
    "# Split dataset to create training ids, validation ids and test ids\n",
    "# Here we have selected the size of test set as 20% which is a common practice.\n",
    "train_ids, test_ids = train_test_split(ids,test_size=0.2) \n",
    "\n",
    "# Create validation ids by further splitting the train ids, we again use 20% as size of valisation set. \n",
    "# Validation set is also referred to as tuning set. \n",
    "\n",
    "train_ids, val_ids = train_test_split(train_ids,test_size=0.2) \n",
    "\n",
    "# Now looks at the number of patient ids in training, validation and test sets\n",
    "print(f'There are {len(train_ids)} patient ids in training set')\n",
    "print(f'There are {len(val_ids)} patient ids in validation set')\n",
    "print(f'There are {len(test_ids)} patient ids in test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wy2rv2pa2elx",
    "outputId": "03f616eb-ec99-4b20-a50e-565d5b26d6ea",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2DcD1xo7l0J",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "def read_patient_niftis(patient_id: str, \n",
    "                        niftis_to_load = ['ctgz', 'kidney_instance-1_annotation-1', 'kidney_instance-1_annotation-2', 'kidney_instance-1_annotation-3', 'kidney_instance-2_annotation-1', 'kidney_instance-2_annotation-2', 'kidney_instance-2_annotation-3'], \n",
    "                        data_path = TRAIN_DATA_PATH):\n",
    "\n",
    "  patient_image_dict = {}\n",
    "  for image in niftis_to_load: \n",
    "    nii_file = Path(data_path, f'{patient_id}', f'{image}.nii')\n",
    "    if os.path.isfile(nii_file):\n",
    "      patient_image_dict[image]=nib.load(nii_file)\n",
    "    else:\n",
    "      nii_gz_file = Path(data_path, f'{patient_id}', f'{image}.nii.gz')\n",
    "      if os.path.isfile(nii_gz_file):\n",
    "        with gzip.open(nii_gz_file, 'rb') as f_in:\n",
    "          with open(nii_file, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "        patient_image_dict[image]=nib.load(nii_file)\n",
    "      else:\n",
    "        raise ValueError(f\"Neither {nii_file} nor {nii_gz_file} exists.\")\n",
    "        \n",
    "  return patient_image_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dknTastw_CeX",
    "outputId": "b0ddb31c-6a72-40aa-9abd-3ba24217fe18",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pt_img_dict = read_patient_niftis(train_ids[10])\n",
    "print(pt_img_dict)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.layers import UpSampling2D\n",
    "\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_WIDTH = 256\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true = K.expand_dims(y_true, axis=-1)\n",
    "    y_pred = K.expand_dims(y_pred, axis=-1)\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true[..., 0], y_pred[..., 0])"
   ],
   "metadata": {
    "id": "QfCISJurUaJ5",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CP2F9Qh3vCUi",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Resizing\n",
    "\n",
    "\n",
    "# Define the UNet model\n",
    "def get_unet(input_shape=(None, None, 1),\n",
    "                  num_classes=1,\n",
    "                  resize_shape=None):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    if resize_shape is not None:\n",
    "        resized = Resizing(resize_shape[0], resize_shape[1])(inputs)\n",
    "        down1 = Conv2D(64, (3, 3), activation = 'relu', padding='same')(resized)\n",
    "    else:\n",
    "        down1 = Conv2D(64, (3, 3), activation = 'relu', padding='same')(inputs)\n",
    "    down1 = BatchNormalization()(down1)\n",
    "    down1 = Conv2D(64, (3, 3), activation = 'relu', padding='same')(down1)\n",
    "    down1 = BatchNormalization()(down1)\n",
    "    down1_pool = MaxPooling2D((2, 2), strides=(2, 2))(down1)\n",
    "\n",
    "\n",
    "    down2 = Conv2D(128, (3, 3), activation = 'relu', padding='same')(down1_pool)\n",
    "    down2 = BatchNormalization()(down2)\n",
    "    down2 = Conv2D(128, (3, 3), activation = 'relu', padding='same')(down2)\n",
    "    down2 = BatchNormalization()(down2)\n",
    "    down2_pool = MaxPooling2D((2, 2), strides=(2, 2))(down2)\n",
    "\n",
    "\n",
    "    down3 = Conv2D(256, (3, 3), activation = 'relu', padding='same')(down2_pool)\n",
    "    down3 = BatchNormalization()(down3)\n",
    "    down3 = Conv2D(256, (3, 3), activation = 'relu', padding='same')(down3)\n",
    "    down3 = BatchNormalization()(down3)\n",
    "    down3_pool = MaxPooling2D((2, 2), strides=(2, 2))(down3)\n",
    " \n",
    "\n",
    "    down4 = Conv2D(512, (3, 3), activation = 'relu', padding='same')(down3_pool)\n",
    "    down4 = BatchNormalization()(down4)\n",
    "    down4 = Conv2D(512, (3, 3), activation = 'relu', padding='same')(down4)\n",
    "    down4 = BatchNormalization()(down4)\n",
    "    down4_pool = MaxPooling2D((2, 2), strides=(2, 2))(down4)\n",
    "\n",
    "\n",
    "    center = Conv2D(1024, (3, 3), activation = 'relu', padding='same')(down4_pool)\n",
    "    center = BatchNormalization()(center)\n",
    "    center = Conv2D(1024, (3, 3), activation = 'relu', padding='same')(center)\n",
    "    center = BatchNormalization()(center)\n",
    "\n",
    "\n",
    "    up4 = UpSampling2D((2, 2))(center)\n",
    "    up4 = concatenate([down4, up4], axis=3)\n",
    "    up4 = Conv2D(512, (3, 3), activation = 'relu', padding='same')(up4)\n",
    "    up4 = BatchNormalization()(up4)\n",
    "    up4 = Conv2D(512, (3, 3), activation = 'relu', padding='same')(up4)\n",
    "    up4 = BatchNormalization()(up4)\n",
    "    up4 = Conv2D(512, (3, 3), activation = 'relu', padding='same')(up4)\n",
    "    up4 = BatchNormalization()(up4)\n",
    "\n",
    "\n",
    "    up3 = UpSampling2D((2, 2))(up4)\n",
    "    up3 = concatenate([down3, up3], axis=3)\n",
    "    up3 = Conv2D(256, (3, 3), activation = 'relu', padding='same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = Conv2D(256, (3, 3), activation = 'relu', padding='same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = Conv2D(256, (3, 3), activation = 'relu', padding='same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    " \n",
    "\n",
    "    up2 = UpSampling2D((2, 2))(up3)\n",
    "    up2 = concatenate([down2, up2], axis=3)\n",
    "    up2 = Conv2D(128, (3, 3), activation = 'relu', padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = Conv2D(128, (3, 3), activation = 'relu', padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = Conv2D(128, (3, 3), activation = 'relu', padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "\n",
    "\n",
    "    up1 = UpSampling2D((2, 2))(up2)\n",
    "    up1 = concatenate([down1, up1], axis=3)\n",
    "    up1 = Conv2D(64, (3, 3), activation = 'relu', padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = Conv2D(64, (3, 3), activation = 'relu', padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = Conv2D(64, (3, 3), activation = 'relu', padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "\n",
    "    classify = Conv2D(num_classes, (1, 1), activation='sigmoid')(up1)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=classify)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.00005), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "    return model\n",
    "\n",
    "model = get_unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rRdWLdvFGqDu",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "outputId": "3b2c5813-51c9-4043-8ec7-097832cfeb9b",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from skimage.transform import resize\n",
    "\n",
    "def read_patient_niftis(patient_id: str, niftis_to_load: List[str], data_path: str) -> dict:\n",
    "    pt_img_dict = {}\n",
    "\n",
    "    for nifti_type in niftis_to_load:\n",
    "        nifti_file_gz = os.path.join(data_path, patient_id, f\"{nifti_type}.nii.gz\")\n",
    "        nifti_file = os.path.join(data_path, patient_id, f\"{nifti_type}.nii\")\n",
    "        \n",
    "        if os.path.exists(nifti_file_gz):\n",
    "            img = nib.load(nifti_file_gz)\n",
    "            pt_img_dict[nifti_type] = (img.get_fdata(), img.shape)\n",
    "        elif os.path.exists(nifti_file):\n",
    "            img = nib.load(nifti_file)\n",
    "            pt_img_dict[nifti_type] = (img.get_fdata(), img.shape)\n",
    "        else:\n",
    "            print(f\"File not found: {nifti_file_gz} or {nifti_file}\")\n",
    "\n",
    "    return pt_img_dict\n",
    "\n",
    "\n",
    "def create_numpy_array(patient_ids: List[str], DATA_PATH: str) -> tuple:\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    niftis_to_load = [\n",
    "        'ctgz', \n",
    "        'kidney_instance-1_annotation-1']\n",
    "    target_shape = (256, 256)\n",
    "\n",
    "    for i in range(len(patient_ids)):\n",
    "        pt_img_dict = read_patient_niftis(patient_ids[i], niftis_to_load, DATA_PATH)\n",
    "\n",
    "        # Check if all Nifti files were loaded successfully\n",
    "        if len(pt_img_dict) < len(niftis_to_load):\n",
    "            print(f\"Skipping patient {patient_ids[i]} due to missing Nifti files\")\n",
    "            continue\n",
    "\n",
    "        images = []\n",
    "        for key, (data, shape) in pt_img_dict.items():\n",
    "            if shape[1] >= 256:  # Add a check to make sure the second dimension is at least 256\n",
    "                # Resize data to the target shape\n",
    "                data_resized = resize(data, target_shape, anti_aliasing=True)\n",
    "                images.append(data_resized)\n",
    "\n",
    "        # Check if images list is not empty before trying to concatenate\n",
    "        if len(images) == 0:\n",
    "            print(f\"Skipping patient {patient_ids[i]} due to empty images list\")\n",
    "            continue\n",
    "\n",
    "        # Resize all images to the same shape\n",
    "        max_shape = max([img.shape for img in images])\n",
    "        images_resized = []\n",
    "        for img in images:\n",
    "            pad_width = [(0, max_shape[i] - img.shape[i]) for i in range(len(max_shape))]\n",
    "            img_padded = np.pad(img, pad_width=pad_width, mode='constant', constant_values=0)\n",
    "            images_resized.append(img_padded)\n",
    "\n",
    "        X.append(np.stack(images_resized[0], axis=1))\n",
    "        Y.append(np.stack(images_resized[1], axis=1))\n",
    "\n",
    "    return np.asarray(X), np.asarray(Y)\n",
    "\n",
    "\n",
    "X_train, Y_train = create_numpy_array(train_ids, TRAIN_DATA_PATH)\n",
    "X_val, Y_val = create_numpy_array(val_ids, TRAIN_DATA_PATH)\n",
    "X_test, Y_test = create_numpy_array(test_ids, TRAIN_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEhKsNspqMmU",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Let's confirm the size of the training, validation and test arrays.\n",
    "print(f'There are {len(X_train)} images in training set')\n",
    "print(f'There are {len(X_val)} images in validation set')\n",
    "print(f'There are {len(X_test)} images in test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yGR_vccoqXYI",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Lets create tensor datasets from numpy arrays\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "dataset_train = dataset_train.map(lambda x, y: {'image': x, 'segmentation_mask': y})\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
    "dataset_val = dataset_val.map(lambda x, y: {'image': x, 'segmentation_mask': y})\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
    "dataset_test = dataset_test.map(lambda x, y: {'image': x, 'segmentation_mask': y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4NT7IOpqaKg",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Let's create image loader to resize the image\n",
    "def load_image(datapoint):\n",
    "    input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
    "    input_masks = []\n",
    "    for mask_key in datapoint.keys():\n",
    "        if 'mask' in mask_key:\n",
    "            input_mask = tf.image.resize(datapoint[mask_key], (128, 128))\n",
    "            input_masks.append(input_mask)\n",
    "    input_mask = tf.stack(input_masks, axis=-1)\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sf3czgaQqfuf",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_LENGTH = len(train_ids)\n",
    "BATCH_SIZE = 4\n",
    "BUFFER_SIZE = 1000\n",
    "STEPS_PER_EPOCH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CmDbHqmkqgjW",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_batches = (\n",
    "    dataset_train\n",
    "    .cache()\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .repeat()\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "\n",
    "val_batches = dataset_val.batch(BATCH_SIZE)\n",
    "test_batches = dataset_test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdjhBkBwrkt4",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# # Let's write a function to show the predictions\n",
    "# dataset = dataset_train\n",
    "# num = 2\n",
    "#\n",
    "# if dataset:\n",
    "#     for image, mask in dataset.take(num):\n",
    "#         pred_mask = model.predict(image)\n",
    "#         display([image[0], mask[0], pred_mask[0]])\n",
    "# else:\n",
    "#     display([sample_image, sample_mask, model.predict(sample_image[tf.newaxis, ...])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bdL04tcNrm10",
    "outputId": "dc9cc042-f1c0-45af-9d71-aec65d4bb9f2",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Lambda, UpSampling2D\n",
    "\n",
    "smooth = 1.\n",
    "EPOCHS = 40\n",
    "VAL_SUBSPLITS = 5\n",
    "VALIDATION_STEPS = len(val_ids)//BATCH_SIZE//VAL_SUBSPLITS\n",
    "optimizer = Adam(learning_rate=0.000007)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "\n",
    "model_history = model.fit(train_batches.map(lambda x: (x['image'], x['segmentation_mask'])), epochs=EPOCHS,\n",
    "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                          validation_data=val_batches.map(lambda x: (x['image'], x['segmentation_mask'])),\n",
    "                          validation_steps=VALIDATION_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's take a look at the learning curve now\n",
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(model_history.epoch, loss, 'r', label='Training loss')\n",
    "plt.plot(model_history.epoch, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim([-1, 0])\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_path = '/Users/syn/Documents/GitHub/KidneySegmentation/kits21/kits21/data'  # path to the directory containing CT images and kidney masks\n",
    "image_size = (256, 256) # desired image size\n",
    "\n",
    "def load_image(file_path):\n",
    "    img = nib.load(file_path).get_fdata()\n",
    "    img = np.rot90(img)  # some .nii files may need to be rotated\n",
    "    img = img[:, :, 0]  # we assume the .nii file contains only one channel\n",
    "    img = img.astype(np.float32) / 255.0  # normalize pixel values to [0, 1]\n",
    "    img = np.clip(img, 0.0, 1.0)  # clip values outside [0, 1]\n",
    "    img = np.expand_dims(cv2.resize(img, image_size), axis=-1)\n",
    "    return img\n",
    "\n",
    "# function to create training data\n",
    "def create_training_data():\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for case in os.listdir(data_path):\n",
    "        case_path = os.path.join(data_path, case)\n",
    "        if os.path.isdir(case_path):\n",
    "            image_path = os.path.join(case_path, 'imaging.nii.gz')\n",
    "            if os.path.isfile(image_path):\n",
    "                has_kidney_mask = False\n",
    "                has_tumor_mask = False\n",
    "                has_cyst_mask = False\n",
    "                for mask_name in os.listdir(os.path.join(case_path, 'segmentations')):\n",
    "                    if mask_name.startswith('kidney_instance') and mask_name.endswith('.nii.gz'):\n",
    "                        mask_path = os.path.join(case_path, 'segmentations', mask_name)\n",
    "                        mask = load_image(mask_path)\n",
    "                        masks.append(mask)\n",
    "                        has_kidney_mask = True\n",
    "                    elif mask_name.startswith('tumor_instance') and mask_name.endswith('.nii.gz'):\n",
    "                        mask_path = os.path.join(case_path, 'segmentations', mask_name)\n",
    "                        mask = load_image(mask_path)\n",
    "                        masks.append(mask)\n",
    "                        has_tumor_mask = True\n",
    "                    elif mask_name.startswith('cyst_instance') and mask_name.endswith('.nii.gz'):\n",
    "                        mask_path = os.path.join(case_path, 'segmentations', mask_name)\n",
    "                        mask = load_image(mask_path)\n",
    "                        masks.append(mask)\n",
    "                        has_cyst_mask = True\n",
    "                if has_kidney_mask and has_tumor_mask and has_cyst_mask:\n",
    "                    image = load_image(image_path)\n",
    "                    images.append(image)\n",
    "                else:\n",
    "                    print(f\"Case {case} excluded: missing kidney and/or tumor and/or cyst mask(s).\")\n",
    "            else:\n",
    "                print(f\"Case {case} excluded: missing imaging file.\")\n",
    "\n",
    "    # convert images and masks to numpy arrays\n",
    "    images = np.array(images)\n",
    "    masks = np.array(masks)\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "# create training data\n",
    "images, masks = create_training_data()\n",
    "\n",
    "# print the shape of the images and masks arrays\n",
    "print('Images shape:', images.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}